{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/c3ilab/Documents/Suryansh/MithilaVerse/env/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "from transformers import GPT2Tokenizer\n",
    "import regex\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_files(directory):\n",
    "    all_texts = []\n",
    "    for file_name in os.listdir(directory):\n",
    "        if file_name.endswith(\".xml\"):\n",
    "            file_path = os.path.join(directory, file_name)\n",
    "            all_texts.extend(load_single_file(file_path))\n",
    "        if file_name.endswith(\".txt\"):\n",
    "            file_path = os.path.join(directory, file_name)\n",
    "            with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                text = file.read()\n",
    "                text_list = text.split('।')\n",
    "                text_list = [segment.strip() for segment in text_list]\n",
    "                all_texts.extend(text_list)\n",
    "    return all_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_single_file(file_path):\n",
    "    texts = []\n",
    "    try:\n",
    "        tree = ET.parse(file_path)\n",
    "        root = tree.getroot()\n",
    "        \n",
    "        # Navigate to the <body> and <p> tags\n",
    "        body = root.find(\".//body\")\n",
    "        if body:\n",
    "            for paragraph in body.findall(\".//p\"):\n",
    "                if paragraph.text:\n",
    "                    texts.append(paragraph.text.strip())\n",
    "    except ET.ParseError as e:\n",
    "        print(f\"Error parsing {file_path}: {e}\")\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    # Replacing multiple spaces with one\n",
    "    text = regex.sub(r\"\\s+\", \" \", text)\n",
    "    # Keep Devanagari and spaces\n",
    "    text = regex.sub(r\"[^\\p{Devanagari}\\s]\", \"\", text)\n",
    "    # Convert to lowercase\n",
    "    text = text.lower().strip()\n",
    "    return text\n",
    "\n",
    "def clean_dataset(dataset):\n",
    "    return [clean_text(text) for text in dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First cleaned sample: ताराशंकर बंधोपाध्यायक जन्म  जुलाई  ईमे पश्चिम बंगालक बीरभूम जिलाक लाभपुर नामक गाममे भेल छल हुनक पिताक नाम श्री हरिदास बंधोपाध्याय और माताक नाम श्रीमती प्रभावती देवी छल ओ परिवारमे सभसँ पैघ छलाह हुनका एकटा बहिन और दूटाभाय छलनि\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    directory = \"Maithili\"\n",
    "    \n",
    "    raw_texts = load_all_files(directory)\n",
    "\n",
    "    cleaned_texts = clean_dataset(raw_texts)\n",
    "\n",
    "    print(\"First cleaned sample:\", cleaned_texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Dataset.from_dict({'text': cleaned_texts})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/c3ilab/Documents/Suryansh/MithilaVerse/env/lib/python3.11/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Map: 100%|██████████| 53951/53951 [00:10<00:00, 5163.23 examples/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "\n",
    "# Set the padding token to be the same as eos_token if it doesn't exist\n",
    "tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "\n",
    "# Tokenize the cleaned dataset\n",
    "def tokenize_function(examples):\n",
    "    # Tokenize inputs and generate labels by shifting the input\n",
    "    encodings = tokenizer(examples['text'], truncation=True, padding='max_length', max_length=512)\n",
    "    encodings['labels'] = encodings['input_ids'].copy()  # Copy the input_ids to labels\n",
    "    return encodings\n",
    "tokenized_data = data.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First tokenized sample: {'text': 'ताराशंकर बंधोपाध्यायक जन्म  जुलाई  ईमे पश्चिम बंगालक बीरभूम जिलाक लाभपुर नामक गाममे भेल छल हुनक पिताक नाम श्री हरिदास बंधोपाध्याय और माताक नाम श्रीमती प्रभावती देवी छल ओ परिवारमे सभसँ पैघ छलाह हुनका एकटा बहिन और दूटाभाय छलनि', 'input_ids': [11976, 97, 48077, 11976, 108, 48077, 11976, 114, 11976, 224, 11976, 243, 11976, 108, 28225, 105, 11976, 224, 11976, 100, 24231, 233, 11976, 103, 48077, 11976, 100, 24231, 235, 11976, 107, 48077, 11976, 107, 11976, 243, 28225, 250, 11976, 101, 24231, 235, 11976, 106, 220, 28225, 250, 24231, 223, 11976, 110, 48077, 11976, 230, 220, 28225, 230, 11976, 106, 24231, 229, 28225, 103, 11976, 114, 24231, 235, 11976, 248, 11976, 123, 11976, 106, 28225, 105, 11976, 224, 11976, 245, 48077, 11976, 110, 11976, 243, 28225, 105, 24231, 222, 11976, 108, 11976, 255, 24231, 224, 11976, 106, 28225, 250, 11976, 123, 11976, 110, 48077, 11976, 243, 28225, 110, 48077, 11976, 255, 11976, 103, 24231, 223, 11976, 108, 28225, 101, 48077, 11976, 106, 11976, 243, 28225, 245, 48077, 11976, 106, 11976, 106, 24231, 229, 28225, 255, 24231, 229, 11976, 110, 28225, 249, 11976, 110, 28225, 117, 24231, 223, 11976, 101, 11976, 243, 28225, 103, 11976, 123, 11976, 97, 48077, 11976, 243, 28225, 101, 48077, 11976, 106, 28225, 114, 24231, 235, 11976, 108, 24231, 222, 28225, 117, 11976, 108, 11976, 123, 11976, 99, 48077, 11976, 116, 28225, 105, 11976, 224, 11976, 100, 24231, 233, 11976, 103, 48077, 11976, 100, 24231, 235, 11976, 107, 48077, 11976, 107, 28225, 242, 11976, 108, 28225, 106, 48077, 11976, 97, 48077, 11976, 243, 28225, 101, 48077, 11976, 106, 28225, 114, 24231, 235, 11976, 108, 24231, 222, 11976, 106, 11976, 97, 24231, 222, 28225, 103, 24231, 235, 11976, 108, 11976, 255, 48077, 11976, 113, 11976, 97, 24231, 222, 28225, 99, 24231, 229, 11976, 113, 24231, 222, 28225, 249, 11976, 110, 28225, 241, 28225, 103, 11976, 108, 11976, 123, 11976, 113, 48077, 11976, 108, 11976, 106, 24231, 229, 28225, 116, 11976, 255, 11976, 116, 11976, 223, 28225, 103, 24231, 230, 11976, 246, 28225, 249, 11976, 110, 48077, 11976, 117, 28225, 117, 24231, 223, 11976, 101, 11976, 243, 48077, 28225, 237, 11976, 243, 11976, 253, 48077, 28225, 105, 11976, 117, 11976, 123, 11976, 101, 28225, 242, 11976, 108, 28225, 99, 24231, 224, 11976, 253, 48077, 11976, 255, 48077, 11976, 107, 28225, 249, 11976, 110, 11976, 101, 11976, 123, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'labels': [11976, 97, 48077, 11976, 108, 48077, 11976, 114, 11976, 224, 11976, 243, 11976, 108, 28225, 105, 11976, 224, 11976, 100, 24231, 233, 11976, 103, 48077, 11976, 100, 24231, 235, 11976, 107, 48077, 11976, 107, 11976, 243, 28225, 250, 11976, 101, 24231, 235, 11976, 106, 220, 28225, 250, 24231, 223, 11976, 110, 48077, 11976, 230, 220, 28225, 230, 11976, 106, 24231, 229, 28225, 103, 11976, 114, 24231, 235, 11976, 248, 11976, 123, 11976, 106, 28225, 105, 11976, 224, 11976, 245, 48077, 11976, 110, 11976, 243, 28225, 105, 24231, 222, 11976, 108, 11976, 255, 24231, 224, 11976, 106, 28225, 250, 11976, 123, 11976, 110, 48077, 11976, 243, 28225, 110, 48077, 11976, 255, 11976, 103, 24231, 223, 11976, 108, 28225, 101, 48077, 11976, 106, 11976, 243, 28225, 245, 48077, 11976, 106, 11976, 106, 24231, 229, 28225, 255, 24231, 229, 11976, 110, 28225, 249, 11976, 110, 28225, 117, 24231, 223, 11976, 101, 11976, 243, 28225, 103, 11976, 123, 11976, 97, 48077, 11976, 243, 28225, 101, 48077, 11976, 106, 28225, 114, 24231, 235, 11976, 108, 24231, 222, 28225, 117, 11976, 108, 11976, 123, 11976, 99, 48077, 11976, 116, 28225, 105, 11976, 224, 11976, 100, 24231, 233, 11976, 103, 48077, 11976, 100, 24231, 235, 11976, 107, 48077, 11976, 107, 28225, 242, 11976, 108, 28225, 106, 48077, 11976, 97, 48077, 11976, 243, 28225, 101, 48077, 11976, 106, 28225, 114, 24231, 235, 11976, 108, 24231, 222, 11976, 106, 11976, 97, 24231, 222, 28225, 103, 24231, 235, 11976, 108, 11976, 255, 48077, 11976, 113, 11976, 97, 24231, 222, 28225, 99, 24231, 229, 11976, 113, 24231, 222, 28225, 249, 11976, 110, 28225, 241, 28225, 103, 11976, 108, 11976, 123, 11976, 113, 48077, 11976, 108, 11976, 106, 24231, 229, 28225, 116, 11976, 255, 11976, 116, 11976, 223, 28225, 103, 24231, 230, 11976, 246, 28225, 249, 11976, 110, 48077, 11976, 117, 28225, 117, 24231, 223, 11976, 101, 11976, 243, 48077, 28225, 237, 11976, 243, 11976, 253, 48077, 28225, 105, 11976, 117, 11976, 123, 11976, 101, 28225, 242, 11976, 108, 28225, 99, 24231, 224, 11976, 253, 48077, 11976, 255, 48077, 11976, 107, 28225, 249, 11976, 110, 11976, 101, 11976, 123, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257]}\n"
     ]
    }
   ],
   "source": [
    "print(\"First tokenized sample:\", tokenized_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/c3ilab/Documents/Suryansh/MithilaVerse/env/lib/python3.11/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Embedding(50258, 768)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import GPT2LMHeadModel, Trainer, TrainingArguments\n",
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=2,\n",
    "    gradient_accumulation_steps=4,  # Simulate a batch size of 8 (2 * 4)\n",
    "    save_steps=10_000,\n",
    "    logging_steps=500,\n",
    "    logging_dir='./logs',\n",
    "    overwrite_output_dir=True,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,                     # The model to be trained\n",
    "    args=training_args,              # Training arguments\n",
    "    train_dataset=tokenized_data,    # The training dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/c3ilab/Documents/Suryansh/MithilaVerse/env/lib/python3.11/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "  2%|▏         | 500/20232 [04:50<3:11:17,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4551, 'learning_rate': 4.8764333728746545e-05, 'epoch': 0.07}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 1000/20232 [09:41<3:04:44,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.338, 'learning_rate': 4.752866745749308e-05, 'epoch': 0.15}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 1500/20232 [14:15<2:48:52,  1.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3082, 'learning_rate': 4.629300118623962e-05, 'epoch': 0.22}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 2000/20232 [18:59<2:58:21,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2996, 'learning_rate': 4.505733491498616e-05, 'epoch': 0.3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 2500/20232 [23:48<2:52:21,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.286, 'learning_rate': 4.382166864373271e-05, 'epoch': 0.37}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 3000/20232 [28:39<2:46:36,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2811, 'learning_rate': 4.258600237247924e-05, 'epoch': 0.44}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 3500/20232 [33:30<2:44:10,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2681, 'learning_rate': 4.1350336101225785e-05, 'epoch': 0.52}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 4000/20232 [38:19<2:36:41,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2637, 'learning_rate': 4.011466982997232e-05, 'epoch': 0.59}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 4500/20232 [43:10<2:33:42,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2623, 'learning_rate': 3.887900355871886e-05, 'epoch': 0.67}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 5000/20232 [48:03<2:28:50,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2548, 'learning_rate': 3.7643337287465405e-05, 'epoch': 0.74}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 5500/20232 [52:52<2:20:45,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2548, 'learning_rate': 3.640767101621194e-05, 'epoch': 0.82}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 6000/20232 [57:43<2:16:45,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.248, 'learning_rate': 3.517200474495848e-05, 'epoch': 0.89}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 6500/20232 [1:02:33<2:14:15,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2435, 'learning_rate': 3.3936338473705025e-05, 'epoch': 0.96}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 7000/20232 [1:07:23<2:08:01,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2384, 'learning_rate': 3.270067220245157e-05, 'epoch': 1.04}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 7500/20232 [1:12:15<2:02:17,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2371, 'learning_rate': 3.14650059311981e-05, 'epoch': 1.11}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 8000/20232 [1:17:06<1:59:25,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2377, 'learning_rate': 3.0229339659944645e-05, 'epoch': 1.19}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 8500/20232 [1:21:57<1:54:53,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2364, 'learning_rate': 2.8993673388691184e-05, 'epoch': 1.26}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 9000/20232 [1:26:47<1:49:07,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.241, 'learning_rate': 2.7758007117437723e-05, 'epoch': 1.33}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 9500/20232 [1:31:38<1:44:34,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2372, 'learning_rate': 2.6522340846184262e-05, 'epoch': 1.41}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 10000/20232 [1:36:29<1:39:57,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2353, 'learning_rate': 2.52866745749308e-05, 'epoch': 1.48}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 10500/20232 [1:41:30<1:32:56,  1.75it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2308, 'learning_rate': 2.4051008303677343e-05, 'epoch': 1.56}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 11000/20232 [1:46:22<1:30:04,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2275, 'learning_rate': 2.2815342032423882e-05, 'epoch': 1.63}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 11500/20232 [1:51:12<1:23:14,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2296, 'learning_rate': 2.1579675761170425e-05, 'epoch': 1.71}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 12000/20232 [1:56:03<1:19:41,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2284, 'learning_rate': 2.0344009489916967e-05, 'epoch': 1.78}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 12500/20232 [2:00:55<1:16:37,  1.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2295, 'learning_rate': 1.9108343218663506e-05, 'epoch': 1.85}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 13000/20232 [2:05:47<1:10:39,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2275, 'learning_rate': 1.7872676947410045e-05, 'epoch': 1.93}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 13500/20232 [2:10:37<1:04:13,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2289, 'learning_rate': 1.6637010676156584e-05, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 14000/20232 [2:15:27<1:01:03,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2253, 'learning_rate': 1.5401344404903126e-05, 'epoch': 2.08}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 14500/20232 [2:20:17<54:39,  1.75it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2185, 'learning_rate': 1.4165678133649665e-05, 'epoch': 2.15}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 15000/20232 [2:25:06<49:55,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.22, 'learning_rate': 1.2930011862396206e-05, 'epoch': 2.22}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 15500/20232 [2:29:55<45:34,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2191, 'learning_rate': 1.1694345591142744e-05, 'epoch': 2.3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 16000/20232 [2:34:44<40:21,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2229, 'learning_rate': 1.0458679319889285e-05, 'epoch': 2.37}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 16500/20232 [2:39:33<35:45,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2284, 'learning_rate': 9.223013048635824e-06, 'epoch': 2.45}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 17000/20232 [2:44:22<31:18,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2158, 'learning_rate': 7.987346777382365e-06, 'epoch': 2.52}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▋ | 17500/20232 [2:49:11<26:06,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2247, 'learning_rate': 6.751680506128904e-06, 'epoch': 2.59}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 18000/20232 [2:54:01<21:22,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2142, 'learning_rate': 5.516014234875446e-06, 'epoch': 2.67}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████▏| 18500/20232 [2:58:51<16:33,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2227, 'learning_rate': 4.2803479636219856e-06, 'epoch': 2.74}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 19000/20232 [3:03:39<11:45,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2195, 'learning_rate': 3.0446816923685253e-06, 'epoch': 2.82}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▋| 19500/20232 [3:08:29<07:01,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2226, 'learning_rate': 1.8090154211150655e-06, 'epoch': 2.89}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 20000/20232 [3:13:21<02:16,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2173, 'learning_rate': 5.733491498616055e-07, 'epoch': 2.97}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20232/20232 [3:15:48<00:00,  1.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 11748.9668, 'train_samples_per_second': 13.776, 'train_steps_per_second': 1.722, 'train_loss': 0.24715846364514166, 'epoch': 3.0}\n"
     ]
    }
   ],
   "source": [
    "trainer.train()\n",
    "trainer.save_model(\"./gpt2-finetuned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Text:  ताराशंकर बंधोपाध्यायक जन्म  जुलाई  भारतक एक भारतीय अभिनेत्री छ ताराशंकर बंधोपाध्यायक जन्म  जुलाई  भारतक एक भारतीय अभिनेत्री छी\n",
      "ताराशंकर बंधोपाध्यायक जन्म  जुलाई  भारतक एक भारतीय अभिनेत्री छ ताराशंकर बंधोपाध्यायक जन्म  जुलाई  भारतक एक भारतीय अभिनेत्री छी\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "import torch\n",
    "\n",
    "# Load your fine-tuned model\n",
    "model = GPT2LMHeadModel.from_pretrained(\"./gpt2-finetuned\")\n",
    "model.to('cuda')\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "\n",
    "input_text = \"ताराशंकर बंधोपाध्यायक जन्म  जुलाई  भारतक एक भारतीय अभिनेत्री छ ताराशंकर बंधोपाध्यायक जन्म  जुलाई  भारतक एक भारतीय अभिनेत्री छ\"  # prompt in Latin script\n",
    "input_ids = tokenizer.encode(input_text, return_tensors='pt')\n",
    "\n",
    "# GPU if available\n",
    "if torch.cuda.is_available():\n",
    "    input_ids = input_ids.cuda()\n",
    "\n",
    "# Generate text\n",
    "output = model.generate(input_ids, max_length=200)  # max_length adjustment\n",
    "generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "print(\"Generated Text: \", generated_text)\n",
    "print(generated_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"abhinavmaithil/maithiliwikidump202009uncleaned\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install kagglehub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
